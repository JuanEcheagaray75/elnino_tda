{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Unveiling ENSO Dynamics:** Insights from Topological Data Analysis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.core.errors import NumbaDeprecationWarning, NumbaPendingDeprecationWarning\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaDeprecationWarning)\n",
    "warnings.simplefilter('ignore', category=NumbaPendingDeprecationWarning)\n",
    "\n",
    "from umap import UMAP\n",
    "# General Software Dependencies\n",
    "# import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "# Mathematical Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "# Dependencias específicas\n",
    "from gtda.time_series import SingleTakensEmbedding\n",
    "from gtda.homology import VietorisRipsPersistence\n",
    "from gtda.diagrams import BettiCurve\n",
    "from gtda.plotting import plot_point_cloud\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.cluster import KMeans\n",
    "import kmapper as km\n",
    "\n",
    "# Plotly parameters\n",
    "# Calculate the desired width and height ratio\n",
    "width_ratio = 10\n",
    "height_ratio = 10\n",
    "# Calculate the desired width based on the height and ratio\n",
    "desired_height = 450  # Choose an appropriate height value\n",
    "desired_width = desired_height * width_ratio / height_ratio\n",
    "margin=dict(l=30, r=30, t=30, b=30)\n",
    "\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_space_separated_file_to_dataframe(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespaces\n",
    "            if line:  # Skip empty lines\n",
    "                items = line.split()  # Split line into separate items\n",
    "                year = items[0]  # First item is the year\n",
    "                months = items[1:]  # Remaining items are months\n",
    "                data.append([year] + months)  # Append year and months to data list\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"Year\"] + list(range(1, 13)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_general_file(file_name):\n",
    "    data = []\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespaces\n",
    "            if line:  # Skip empty lines\n",
    "                items = line.split()  # Split line into separate items\n",
    "                year = items[0]  # First item is the year\n",
    "                months = items[1:]  # Remaining items are months\n",
    "                data.append([year] + months)  # Append year and months to data list\n",
    "\n",
    "    gen_df = pd.DataFrame(data)\n",
    "    gen_df.columns = gen_df.iloc[0]\n",
    "    gen_df = gen_df[1:]\n",
    "    gen_df['date'] = pd.to_datetime(gen_df[\"YR\"].astype(str) + \"-\" + gen_df[\"MON\"].astype(str), format=\"%Y-%m\")\n",
    "    gen_df.set_index('date', inplace=True)\n",
    "    gen_df.columns = ['year', 'month', 'nino1.2', 'anom_nino1.2',\n",
    "                  'nino3', 'anom_nino3','nino4', 'anom_nino4',\n",
    "                  'nino3.4', 'anom_nino3.4']\n",
    "    \n",
    "    gen_df = gen_df.apply(pd.to_numeric)\n",
    "    gen_df = gen_df.sort_index()\n",
    "\n",
    "    return gen_df\n",
    "\n",
    "\n",
    "def fit_embedder(embedder: SingleTakensEmbedding, y: np.ndarray, verbose: bool=True):\n",
    "    \"\"\"Fits a Takens embedder and displays optimal search parameters.\"\"\"\n",
    "    \n",
    "    y_embedded = embedder.fit_transform(y)\n",
    "    delay = embedder.time_delay_\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Shape of embedded time series: {y_embedded.shape}\")\n",
    "        print(\n",
    "            f\"Optimal embedding dimension is {embedder.dimension_} and time delay is {delay:.4f}\"\n",
    "        )\n",
    "\n",
    "    return y_embedded, delay\n",
    "\n",
    "\n",
    "def periodicity_analysis(max_embedding_dimension: int, \n",
    "                         max_time_delay: int, \n",
    "                         stride: int, \n",
    "                         y: pd.Series, \n",
    "                         var_name: str,\n",
    "                         cluster: callable, \n",
    "                         persistence: callable):\n",
    "    \n",
    "\n",
    "    embedder = SingleTakensEmbedding(\n",
    "        parameters_type=\"search\",\n",
    "        n_jobs=-1,\n",
    "        time_delay=max_time_delay,\n",
    "        dimension=max_embedding_dimension,\n",
    "        stride=stride,\n",
    "    )\n",
    "    y_embedded, delay = fit_embedder(embedder, y)\n",
    "    print(f\"Time delay: {delay}\")\n",
    "\n",
    "    fig = go.Figure(data=go.Scatter(\n",
    "                        x=y.index.astype(str), \n",
    "                        y=y,\n",
    "                        marker_color='indianred', \n",
    "                        text=f\"{var_name} idx\")\n",
    "                    )\n",
    "    fig.update_layout({\"title\": f'Time series for: {var_name}',\n",
    "                    \"xaxis\": {\"title\":\"Date\"},\n",
    "                    \"yaxis\": {\"title\":f\"{var_name} idx\"},\n",
    "                    \"showlegend\": False,\n",
    "                    \"width\": desired_width*2.11,\n",
    "                    \"height\": desired_height})\n",
    "    \n",
    "    fig.write_image(f'docs/img/{var_name}_time_series.png', scale=2)\n",
    "    fig.show()\n",
    "        \n",
    "    y_embedded_trans = cluster.fit_transform(y_embedded)\n",
    "    proj_series_fig = plot_point_cloud(y_embedded_trans[:, :3])\n",
    "\n",
    "    margin=dict(l=20, r=20, t=30, b=30)\n",
    "    proj_series_fig.update_layout(\n",
    "        title=f'Encaje de {var_name}',\n",
    "        width=desired_width,\n",
    "        height=desired_height,\n",
    "        margin=margin\n",
    "        )\n",
    "    \n",
    "    proj_series_fig.write_image(f'docs/img/{var_name}_projection.png', scale=2)\n",
    "    proj_series_fig.show()\n",
    "\n",
    "    pers_vals = persistence.fit_transform(y_embedded_trans[None, :, :])\n",
    "    pers_fig = persistence.plot(pers_vals)\n",
    "    pers_fig.update_layout(\n",
    "        title=f'Diagrama de Persistencia de {var_name}',\n",
    "        height=desired_height\n",
    "    )\n",
    "    pers_fig.write_image(f'docs/img/{var_name}_persistence.png', scale=2)\n",
    "    pers_fig.show()\n",
    "\n",
    "    bettis = BettiCurve()\n",
    "    bet_vals = bettis.fit_transform(pers_vals)\n",
    "    betti_fig = bettis.plot(bet_vals)\n",
    "    betti_fig.update_layout(\n",
    "        title=f'Curvas de Betti de {var_name}',\n",
    "        width=desired_width,\n",
    "        height=desired_height\n",
    "        )\n",
    "    \n",
    "    betti_fig.write_image(f'docs/img/{var_name}_betti_curve.png', scale=2)\n",
    "    betti_fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = parse_space_separated_file_to_dataframe('db/nino34.long.anom.data.txt')\n",
    "df = df.melt(id_vars=[\"Year\"], var_name=\"Month\", value_name='anom_nino3.4')\n",
    "df[\"date\"] = pd.to_datetime(df[\"Year\"].astype(str) + \"-\" + df[\"Month\"].astype(str), format=\"%Y-%m\")\n",
    "df = df[['date', 'anom_nino3.4']]\n",
    "df = df.set_index('date')\n",
    "df['anom_nino3.4'] = df['anom_nino3.4'].astype(float)\n",
    "df = df.sort_index()\n",
    "\n",
    "gen_df = parse_general_file('db/sstoi.indices.txt')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de periodicidad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nino 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'nino1.2'\n",
    "delta = 15\n",
    "start = 1980  - 6*delta\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(1995, 1, 1)\n",
    "data = gen_df[var] # [dt_start:dt_end][var]\n",
    "\n",
    "\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "se = SpectralEmbedding(n_components=4, random_state=0)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=se,\n",
    "                     persistence=persistence\n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalías Nino 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1980, 1995\n",
    "var = 'anom_nino1.2'\n",
    "dt_start = datetime(2000, 1, 1)\n",
    "dt_end = datetime(2020, 1, 1)\n",
    "data = gen_df[var] #[dt_start:dt_end][var]\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "\n",
    "#UMAP\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Niño 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'nino3'\n",
    "delta = 15\n",
    "start = 1980  - 6*delta\n",
    "dt_start = datetime(1992, 1, 1)\n",
    "dt_end = datetime(2005, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "\n",
    "\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "se = SpectralEmbedding(n_components=4, random_state=0)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,  \n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalías Nino 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'anom_nino3'\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(1995, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "\n",
    "#UMAP\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence\n",
    "                     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nino 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1980, 1995\n",
    "var = 'nino4'\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(1997, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalías Nino 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1980, 1995\n",
    "var = 'anom_nino4'\n",
    "data = gen_df[var]#[dt_start:dt_end][var]\n",
    "\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nino 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1980, 1995\n",
    "var = 'nino3.4'\n",
    "dt_start = datetime(1982, 1, 1)\n",
    "dt_end = datetime(2006, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 13\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalías Nino 3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1980, 1995\n",
    "var = 'anom_nino3.4'\n",
    "delta = 15\n",
    "start = 1980  - 6*delta\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(1995, 1, 1)\n",
    "data = gen_df[var]#[dt_start:dt_end][var]\n",
    "data = gen_df[dt_start:dt_end][var]\n",
    "\n",
    "max_embedding_dimension = 10\n",
    "max_time_delay = 10\n",
    "stride = 1\n",
    "um  = UMAP(random_state=0, n_components=4)\n",
    "y = data\n",
    "var_name = var\n",
    "persistence = VietorisRipsPersistence(\n",
    "    homology_dimensions=[0, 1, 2],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "periodicity_analysis(max_embedding_dimension=max_embedding_dimension,\n",
    "                     max_time_delay=max_time_delay,\n",
    "                     stride=stride,\n",
    "                     y=y,\n",
    "                     var_name=var_name,\n",
    "                     cluster=um,\n",
    "                     persistence=persistence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconocimiento de patrones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'nino3.4'\n",
    "\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(2023, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][['year', 'month', f'{var}', f'anom_{var}']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data, x=f'{var}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moño\n",
    "\n",
    "Se proyecta el año, mes, temperatura e índice de anomalía de Nino3.4 a el índice de anomalía Nino3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'nino3.4'\n",
    "\n",
    "dt_start = datetime(1980, 1, 1)\n",
    "dt_end = datetime(2023, 1, 1)\n",
    "data = gen_df[dt_start:dt_end][['year', 'month', f'{var}', f'anom_{var}']]\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=0)\n",
    "projected_data = mapper.fit_transform(\n",
    "    X=data.to_numpy(), \n",
    "    projection=[\n",
    "        3\n",
    "    ]\n",
    ")\n",
    "covering=km.Cover(n_cubes=4,\n",
    "                  perc_overlap=0.2)\n",
    "\n",
    "G = mapper.map(projected_data, data,\n",
    "               clusterer=KMeans(n_clusters=4, random_state=0, n_init='auto'),\n",
    "               cover=covering)\n",
    "fig = mapper.visualize(G, \n",
    "                path_html='graphs/noaa_temp_anom_nino34.html',\n",
    "                title=f'Dates, Nino 3.4 temps and Anom Nino 3.4 Idx proj. to Nino 3.4 Anom Idx',\n",
    "                custom_tooltips = data.index,\n",
    "                color_values = gen_df[dt_start:dt_end]['nino3.4'],\n",
    "                color_function_name = 'Nino 3.4 temperatures',\n",
    "                node_color_function=np.array(['max', 'average','std','sum', 'min', 'median'])\n",
    "            )\n",
    "\n",
    "!explorer.exe \"graphs\\\\noaa_temp_anom_nino34.html\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuerda\n",
    "\n",
    "Se genera una clusterización basada solamente en las mediciones de anomalías de Nino3.4 (forma un gusanito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous 1870 - 2018\n",
    "\n",
    "dt_start = datetime(1870, 1, 1)\n",
    "dt_end = datetime(2018, 1, 1)\n",
    "data = df[dt_start:dt_end]\n",
    "data['month'] = data.index.month\n",
    "data['year'] = data.index.year\n",
    "data = data[['month', 'year', 'anom_nino3.4']]\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=0)\n",
    "\n",
    "projected_data = mapper.fit_transform(\n",
    "    X=data.to_numpy(), \n",
    "    projection=[\n",
    "        2\n",
    "    ]\n",
    ")\n",
    "covering=km.Cover(n_cubes=2,\n",
    "                  perc_overlap=0.1)\n",
    "\n",
    "G = mapper.map(projected_data, data,\n",
    "               clusterer=KMeans(n_clusters=4, \n",
    "                                random_state=0, \n",
    "                                n_init='auto'),\n",
    "               cover=covering)\n",
    "fig = mapper.visualize(G,\n",
    "                path_html='graphs/climateai_anom_nino34.html',\n",
    "                title=f'Dates and Nino 3.4 index proj. to Nino 3.4 Index',\n",
    "                custom_tooltips = data.index,\n",
    "                color_values = data['anom_nino3.4'],\n",
    "                color_function_name = 'Anom Nino 3.4',\n",
    "                node_color_function=['max', 'average','std','sum','min']\n",
    "            )\n",
    "\n",
    "!explorer.exe \"graphs\\\\climateai_anom_nino34.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_node = data.iloc[G['nodes']['cube1_cluster3']]\n",
    "cold_node = data.iloc[G['nodes']['cube0_cluster1']]\n",
    "hot_node_2 = data.iloc[G['nodes']['cube1_cluster1']]\n",
    "cold_node_2 = data.iloc[G['nodes']['cube0_cluster0']]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot the time series of anom_nino3.4 from the hot node\n",
    "plt.plot(hot_node.index, \n",
    "         hot_node['anom_nino3.4'], \n",
    "         label='Hot node', \n",
    "         marker='o',\n",
    "         markersize=3,\n",
    "         lw=1)\n",
    "# Plot the time series of anom_nino3.4 from the cold node\n",
    "plt.plot(cold_node.index, \n",
    "         cold_node['anom_nino3.4'], \n",
    "         label='Cold node',\n",
    "         marker='o',\n",
    "         markersize=3,\n",
    "         lw=1)\n",
    "# Plot the time series of anom_nino3.4 from the hot node\n",
    "plt.plot(hot_node_2.index,\n",
    "            hot_node_2['anom_nino3.4'],\n",
    "            label='Hot node 2',\n",
    "            marker='o',\n",
    "            markersize=3,\n",
    "            lw=1)\n",
    "# Plot the time series of anom_nino3.4 from the cold node\n",
    "plt.plot(cold_node_2.index,\n",
    "            cold_node_2['anom_nino3.4'],\n",
    "            label='Cold node 2',\n",
    "            marker='o',\n",
    "            markersize=3,\n",
    "            lw=1)\n",
    "\n",
    "plt.plot\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Anom Nino 3.4')\n",
    "plt.title('Time series of anom_nino3.4 from the hot and cold nodes')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_start = datetime(1870, 1, 1)\n",
    "dt_end = datetime(2018, 1, 1)\n",
    "data = df[dt_start:dt_end]\n",
    "data['month'] = data.index.month\n",
    "data['year'] = data.index.year\n",
    "data = data[['month', 'year', 'anom_nino3.4']]\n",
    "\n",
    "mapper = km.KeplerMapper(verbose=0)\n",
    "projected_data = mapper.fit_transform(\n",
    "    X=data.to_numpy(), \n",
    "    projection=[\n",
    "        2\n",
    "    ]\n",
    ")\n",
    "\n",
    "covering=km.Cover(n_cubes=3,\n",
    "                  perc_overlap=0.2)\n",
    "\n",
    "G = mapper.map(projected_data, data,\n",
    "               clusterer=KMeans(n_clusters=4, \n",
    "                                random_state=0, \n",
    "                                n_init='auto'),\n",
    "               cover=covering)\n",
    "fig = mapper.visualize(G,\n",
    "                path_html='graphs/climateai_anom_nino34_realistic.html',\n",
    "                title=f'Dates, Nino 3.4 temps and Nino 3.4 index proj. to Nino 3.4 Index',\n",
    "                custom_tooltips = data.index,\n",
    "                color_values = data['anom_nino3.4'],\n",
    "                color_function_name = 'Anom Nino 3.4',\n",
    "                node_color_function=np.array(['average','std','sum','max','min'])\n",
    "            )\n",
    "\n",
    "!explorer.exe \"graphs\\\\climateai_anom_nino34_realistic.html\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de pronóstico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from gtda.diagrams import Amplitude\n",
    "from gtda.homology import VietorisRipsPersistence, WeakAlphaPersistence\n",
    "from gtda.time_series import (\n",
    "    Labeller,\n",
    "    SlidingWindow,\n",
    "    TakensEmbedding\n",
    ")\n",
    "from gtda.pipeline import make_pipeline\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred = 40\n",
    "y = data['anom_nino3.4']\n",
    "\n",
    "y_train, y_test = temporal_train_test_split(y, test_size=n_pred)\n",
    "mape = MeanAbsolutePercentageError(symmetric=False)\n",
    "smape = MeanAbsolutePercentageError(symmetric=True)\n",
    "\n",
    "Lab = Labeller(size=1, func=np.max)\n",
    "_, _ = Lab.fit_transform_resample(y_train, y_train)\n",
    "SW = SlidingWindow(size=n_pred)\n",
    "TE = TakensEmbedding(time_delay=1, dimension=5)\n",
    "VR = VietorisRipsPersistence()\n",
    "WA = WeakAlphaPersistence()\n",
    "Ampl = Amplitude()\n",
    "XGB = XGBRegressor()\n",
    "\n",
    "pipe = make_pipeline(Lab, SW, TE, VR, Ampl, XGB)\n",
    "pipe.fit(y_train, y_train)\n",
    "y_pred = pipe.predict(y_train)\n",
    "\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{100*pipe.score(y_train, y_train) = :.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = pd.Series(\n",
    "    y_pred,\n",
    "    index=pd.date_range(start=y_train.index[n_pred], \n",
    "                        end=y_train.index[-1].to_pydatetime(),\n",
    "                        freq='MS')\n",
    ")\n",
    "yt_plot = y_train[n_pred:] \n",
    "min_date, max_date = 1880, 1940\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(yt_plot[datetime(min_date, 1, 1):datetime(max_date, 1, 1)], label='correct')\n",
    "plt.plot(full_pred[datetime(min_date, 1, 1):datetime(max_date, 1, 1)], label='predicted')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.title(f'ML TDA informed Forecasting Model for Nino 3.4 Index {min_date}-{max_date}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Anom Nino 3.4 Idx')\n",
    "plt.savefig(f'graphs/forecasting_{min_date}_{max_date}.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = y_train.index[-1].to_pydatetime() + relativedelta(months=1)\n",
    "pred_idx = pd.date_range(start_idx, periods=n_pred, freq='MS')\n",
    "pred_series = pd.Series(y_pred[-n_pred:], index=pred_idx)\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "plt.plot(y_test, label='correct')\n",
    "plt.plot(pred_series, label='predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ML TDA informed Forecasting Model')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Anom Nino 3.4 Idx')\n",
    "plt.savefig(f'graphs/forecasting_test.png',\n",
    "            dpi=300,\n",
    "            bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct index type to avoid error\n",
    "pred_series.index = y_test.index\n",
    "\n",
    "mape_error = mape(y_test, pred_series)\n",
    "smape_error = smape(y_test, pred_series)\n",
    "\n",
    "print(f'''Forecasting Summary:\n",
    "{mape_error = :.2f} %\n",
    "{smape_error = :.2f} %\n",
    "''')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
